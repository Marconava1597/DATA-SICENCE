{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BUj8h94_2WVp",
        "uf5mOSXJ5sE6",
        "FipIcB8E62mN",
        "jTxZuK3l7dDe"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transformación, filtración y ordenamiento de datos"
      ],
      "metadata": {
        "id": "p4Q3gScXyCUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hoy aprenderemos algunas técnicas para realizar transformación y reestructuración de datos.\n",
        "\n",
        "La transformación de datos consiste en convertir un dato en otro dato utilizando algún tipo de proceso transformativo.\n",
        "\n",
        "La reestructuración de datos tiene que ver con ver tu conjunto de datos desde diferentes perspectivas.\n",
        "\n",
        "La transformación es muy útil para limpiar nuestro dataset y para dejarlo preparado para futuros análisis estadísticos, mientras que la reestructuración nos ayuda a entender mejor nuestro conjunto de datos y extraer información valiosa que pueda ser luego analizada o visualizada."
      ],
      "metadata": {
        "id": "yIHZRnuO0quo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenación de Series\n",
        "\n"
      ],
      "metadata": {
        "id": "G0lru6Svhk-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando obtenemos nuestros datos en \"cachitos\", como cuando hacemos peticiones a una API, necesitamos luego unir todos nuestros datos en un solo DataFrame. Para eso podemos usar la función pd.concat de pandas. Primero vamos a aprender los principios básicos usando Series, para luego poder aplicar esos mismos principios a los DataFrames."
      ],
      "metadata": {
        "id": "vanKIQR-huIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "ni1OS_NVhD1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serie_1 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
        "serie_2 = pd.Series([4, 5, 6], index=['d', 'f', 'e'])"
      ],
      "metadata": {
        "id": "6DGOJcbYhykn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([serie_1, serie_2], axis=0)\n"
      ],
      "metadata": {
        "id": "UWJcOLhph0Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "También podemos concatenar horizontalmente:\n",
        "\n"
      ],
      "metadata": {
        "id": "Ze9hBXhLiYIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([serie_1, serie_2], axis=1)\n"
      ],
      "metadata": {
        "id": "A8sgGtXDiSsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos nombrar nuestras columnas para saber cuál era cuál:\n",
        "\n"
      ],
      "metadata": {
        "id": "iV8jiC53ixJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([serie_1, serie_2], axis=1, keys=['serie_1', 'serie_2'])\n"
      ],
      "metadata": {
        "id": "0MTaPp5fiUwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto pasa si concatenamos horizontalmente usando el mismo índice:\n",
        "\n"
      ],
      "metadata": {
        "id": "yRIPGZtLizaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "serie_3 = pd.Series([7, 8, 9], index=['a', 'b', 'c'])\n",
        "\n",
        "pd.concat([serie_1, serie_3], axis=1, keys=['serie_1', 'serie_3'])"
      ],
      "metadata": {
        "id": "UKJBRVCWi1HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si concatenamos verticalmente dos Series que comparten el índice, tenemos el problema de no poder diferenciar los índices:\n",
        "\n"
      ],
      "metadata": {
        "id": "XnpmMXgNi26K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([serie_1, serie_3], axis=0)\n"
      ],
      "metadata": {
        "id": "xBOWwJB_i4u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A veces queremos esto, pero cuando no, podemos agregar un segundo nivel de índice para hacer la diferencia:\n",
        "\n"
      ],
      "metadata": {
        "id": "xhnY4tEJjWhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([serie_1, serie_3], axis=0, keys=['serie_1', 'serie_3'])\n"
      ],
      "metadata": {
        "id": "TI-eCxhrjZUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto se llama un Multiíndice. Podemos acceder a un multiíndice en un solo nivel o en ambos:\n",
        "\n"
      ],
      "metadata": {
        "id": "MArRzMHIjvI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series_concat = pd.concat([serie_1, serie_3], axis=0, keys=['serie_1', 'serie_3'])\n"
      ],
      "metadata": {
        "id": "0vU1HnpxjuBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series_concat.loc['serie_1']\n"
      ],
      "metadata": {
        "id": "q-hwPR0pjxHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series_concat.loc[('serie_1', 'b')]\n"
      ],
      "metadata": {
        "id": "ZTgqh896jyib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenación de DataFrames"
      ],
      "metadata": {
        "id": "05ZMul5gj-kE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los mismos principios de concatenación aplican tanto a Series como a DataFrames. Vamos a verlos en acción y realizar una práctica para que nos quede todo súper claro."
      ],
      "metadata": {
        "id": "eVOIki-BkCCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_1 = {\n",
        "    'column_1': [1, 2, 3],\n",
        "    'column_2': [4, 5, 6]\n",
        "}\n",
        "\n",
        "df_1 = pd.DataFrame(data_1, index=['a', 'b', 'c'])\n",
        "\n",
        "df_1"
      ],
      "metadata": {
        "id": "k-TZpMBLkIca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_2 = {\n",
        "    'column_1': [7, 8, 9],\n",
        "    'column_2': [10, 11, 12]\n",
        "}\n",
        "\n",
        "df_2 = pd.DataFrame(data_1, index=['d', 'e', 'f'])\n",
        "\n",
        "df_2"
      ],
      "metadata": {
        "id": "6XtjPtnDkMlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df_1, df_2], axis=0)\n"
      ],
      "metadata": {
        "id": "693qt2C0kOVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df_1, df_2], axis=1)\n"
      ],
      "metadata": {
        "id": "SzizVBTikQe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_3 = {\n",
        "    'column_3': [7, 8, 9],\n",
        "    'column_4': [10, 11, 12]\n",
        "}\n",
        "\n",
        "df_3 = pd.DataFrame(data_3, index=['a', 'b', 'c'])\n",
        "\n",
        "df_3"
      ],
      "metadata": {
        "id": "zMWB4HUWkSPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df_1, df_3], axis=1)\n"
      ],
      "metadata": {
        "id": "hH0wL8YFkT6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si concatenamos verticalmente con el mismo índice, no podemos diferenciarlos:\n",
        "\n"
      ],
      "metadata": {
        "id": "MtP0MG7FkV-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_4 = {\n",
        "    'column_1': [7, 8, 9],\n",
        "    'column_2': [10, 11, 12]\n",
        "}\n",
        "\n",
        "df_4 = pd.DataFrame(data_4, index=['a', 'b', 'c'])\n",
        "\n",
        "df_4"
      ],
      "metadata": {
        "id": "I62U0JMgkZw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df_1, df_4], axis=0)\n"
      ],
      "metadata": {
        "id": "3yqQijnCkbnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concat = pd.concat([df_1, df_4], axis=0, keys=['df_1', 'df_4'])\n",
        "\n",
        "df_concat"
      ],
      "metadata": {
        "id": "wUoPQcEhkdPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concat.loc['df_1']\n"
      ],
      "metadata": {
        "id": "nRXJ6_ULke9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_concat.loc[('df_1', 'b')]\n"
      ],
      "metadata": {
        "id": "5cYM6bhYkgjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Automatizando peticiones"
      ],
      "metadata": {
        "id": "sl3pbU12mr0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time"
      ],
      "metadata": {
        "id": "j0LqbyeuneeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos cómo usar todo lo que aprendimos para automatizar el proceso de realizar múltiples peticiones a la API, reunirlas en un DataFrame"
      ],
      "metadata": {
        "id": "1Jcv-fMcmtJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = 'https://api.nasa.gov/neo/rest/v1/neo/browse/'\n",
        "payload = {'api_key': 'tu_api_key_va_aqui'}"
      ],
      "metadata": {
        "id": "GaqtaQPbnV1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_datos = {}\n",
        "\n",
        "for i in range(0, 10):\n",
        "    \n",
        "    try:\n",
        "        time.sleep(5)\n",
        "        r = requests.get(endpoint, params=payload, timeout=5)\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            json = r.json()\n",
        "\n",
        "            data = json['near_earth_objects']\n",
        "            dict_datos[i] = data\n",
        "\n",
        "            new_link = json['links']['next']\n",
        "            endpoint = new_link\n",
        "    except:\n",
        "        continue"
      ],
      "metadata": {
        "id": "m7uCWBvAnYlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in dict_datos:\n",
        "    normalized = pd.json_normalize(dict_datos[key])\n",
        "    df = pd.DataFrame.from_dict(normalized)\n",
        "    dict_datos[key] = df"
      ],
      "metadata": {
        "id": "qlBR569fnZS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_de_dataframes = []\n",
        "\n",
        "for key in dict_datos:\n",
        "    lista_de_dataframes.append(dict_datos[key])"
      ],
      "metadata": {
        "id": "bD3iQSiZnjn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_completo = pd.concat(lista_de_dataframes, axis=0).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "UMwp0u7xnlMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_completo\n"
      ],
      "metadata": {
        "id": "Q8dvIpEJnnFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CASTING"
      ],
      "metadata": {
        "id": "BUj8h94_2WVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El primer tipo de transformación que veremos es el casting. Casting significa convertir un dato de un tipo de dato a otro tipo de dato. O sea, convertir una string a un int, un int a un float, un int a un datetime, etc.\n",
        "\n",
        "Muchas veces los conjuntos de datos con los que nos topamos no tienen el formato adecuado o están muy sucios. Esto ocasiona que pandas no sepa cómo interpretar el tipo de datos con los que se enfrenta.\n",
        "\n",
        "Veremos algunas técnicas parar hacer casting manualmente en los casos en los que pandas se equivoque o no sepa cómo proceder.\n",
        "\n"
      ],
      "metadata": {
        "id": "6QhSdmeJ2Ztj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6T8defTxjW2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../../Datasets/new_york_times_bestsellers-dirty.csv', index_col=0)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "zoF3iT4y2mRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes\n"
      ],
      "metadata": {
        "id": "nfJLJyOI2pam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Específicamente, tenemos dos columnas con fechas (bestsellers_date.numberLong y published_date.numberLong) que tienen tipos object e int64. También tenemos una columna rank.numberInt que no tiene el tipo de dato adecuado.\n",
        "\n",
        "Podemos usar el método astype para pasarle a nuestro DataFrame un diccionario de conversión. Por ejemplo, vamos a convertir nuestras dos columnas de fechas usando un diccionario de conversión. El tipo de dato que usamos para manejar fechas es el llamado datetime. Este tipo de dato nos permite manipular fechas y horarios muy eficientemente."
      ],
      "metadata": {
        "id": "qNm6K9vu2tSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diccionario_de_conversion = {\n",
        "    'bestsellers_date.numberLong': 'datetime64[ns]',\n",
        "    'published_date.numberLong': 'datetime64[ns]'\n",
        "}\n"
      ],
      "metadata": {
        "id": "3nHSO5-F2t-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "temp = df.astype(diccionario_de_conversion)\n",
        "\n",
        "temp.head()\n"
      ],
      "metadata": {
        "id": "jZYODTf13mL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.dtypes\n"
      ],
      "metadata": {
        "id": "uMZp_XJ43psr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como puedes ver, nuestras columnas han sido transformadas. Pero parece que hay un problema, puesto que hay muchísima diferencia de años entre la columna bestsellers_date y la columna published_date. Esto se debe a que published_date está en formato 'milisegundos desde La Época (la medianoche UTC del 1 de enero de 1970)' y pandas asume por default que estamos lidiando con nanosegundos.\n",
        "\n",
        "Para evitar este problema vamos a usar el método pd.to_datetime para convertir published_date:"
      ],
      "metadata": {
        "id": "uT2J6Klx3sNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.to_datetime(df['published_date.numberLong'], unit='ms')\n"
      ],
      "metadata": {
        "id": "fpalw3UG3uqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to_datetime nos permite especificar las unidades para que la conversión se realice con éxito.\n",
        "\n",
        "Vamos ahora qué pasa si queremos convertir rank.numberInt usando astype:"
      ],
      "metadata": {
        "id": "xRuG-3MK4UaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['rank.numberInt'].astype(int)\n"
      ],
      "metadata": {
        "id": "mgu0WoIo4WAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No podemos hacerlo porque hay unos valores tipo string que no pueden ser convertidos a int. Para esto usamos el método to_numeric, que nos permite indicar que cuando un error sea encontrado, debe de ser sustituido por un NaN:\n",
        "\n"
      ],
      "metadata": {
        "id": "12QwnrEI4ZP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.to_numeric(df['rank.numberInt'], errors='coerce')\n"
      ],
      "metadata": {
        "id": "zDSz3_WZ4a0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a reasignar el resultado al DataFrame original:\n",
        "\n"
      ],
      "metadata": {
        "id": "9RY_F4OT5RE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['rank.numberInt'] = pd.to_numeric(df['rank.numberInt'], errors='coerce')\n"
      ],
      "metadata": {
        "id": "X0OEzax15Rdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, para convertirlo a tipo int podemos eliminar los NaNs y luego usar astype:\n",
        "\n"
      ],
      "metadata": {
        "id": "J7r1Z0RD5UN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(axis=0).copy()\n"
      ],
      "metadata": {
        "id": "2dDg7qpM5Uz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['rank.numberInt'] = df['rank.numberInt'].astype(int)\n"
      ],
      "metadata": {
        "id": "tNmCGOHf5dvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes\n"
      ],
      "metadata": {
        "id": "0_vRc6685fZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manipulación de strings"
      ],
      "metadata": {
        "id": "uf5mOSXJ5sE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manipular strings es todo un tema por sí mismo. Aprender a usar las herramientas de manipulación de strings es muy importante puesto que nos permite trabajar con datos no estructurados. Los datos no estructurados son básicamente secuencias de caracteres tipo texto.\n",
        "\n",
        "Dado que en un texto las configuraciones, patrones y significados posibles son casi infinitos, necesitamos técnicas que nos ayuden a lidiar a mucho detalle con estos datos.\n",
        "\n",
        "Para eso tenemos la propiedad str que estudiaremos a continuación."
      ],
      "metadata": {
        "id": "kDflvxVO5xCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empecemos con la columna description que tiene un 'Descr:' al inicio de cada texto. Si queremos remover ese texto podemos usar el método replace de la propiedad str de esa Serie:"
      ],
      "metadata": {
        "id": "iL2e4Ed16ArU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['description'].str.replace('Descr:', '')\n"
      ],
      "metadata": {
        "id": "2BGWgmzG6HBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['description'] = df['description'].str.replace('Descr:', '')\n"
      ],
      "metadata": {
        "id": "ND5Ki7H_6JcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[0, 'description']\n"
      ],
      "metadata": {
        "id": "2H64RDTj6LBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como puedes ver, tenemos también espacios vacíos al principio y final de nuestras strings. Vamos a removerlos usando strip:\n",
        "\n"
      ],
      "metadata": {
        "id": "oSCHxpXq6MxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['description'].str.strip()\n"
      ],
      "metadata": {
        "id": "rxg-O_Bi6TZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['description'] = df['description'].str.strip()\n"
      ],
      "metadata": {
        "id": "k03mOqyG6VJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[0, 'description']\n"
      ],
      "metadata": {
        "id": "HcJUvEPF6WxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora veamos la columna 'title', cuyos textos están en mayúsculas. Esto no es muy agradable, así que podemos usar algunos métodos para modificar el patrón de mayúsculas y minúsculas:"
      ],
      "metadata": {
        "id": "PtgXtYL06Yoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['title'].str.lower()\n"
      ],
      "metadata": {
        "id": "uKol9BHD6aLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title'].str.title()\n"
      ],
      "metadata": {
        "id": "axKQgECV6bqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title'] = df['title'].str.title()\n"
      ],
      "metadata": {
        "id": "orrTq2OW6djj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, digamos que queremos separar nuestra columna author en dos columnas author_first_name y author_last_name. Eso lo podemos hacer con el método split:"
      ],
      "metadata": {
        "id": "Z6s9Gzvv6fTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['author'].str.split(' ')\n"
      ],
      "metadata": {
        "id": "0wcWJkIu6f9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['author'].str.split(' ', expand=True)\n"
      ],
      "metadata": {
        "id": "_2f0ghOL6v9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['author_first_name', 'author_last_name']] = df['author'].str.split(' ', expand=True)\n"
      ],
      "metadata": {
        "id": "ykcuryy36xhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "rhmM0alo6zCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAP"
      ],
      "metadata": {
        "id": "FipIcB8E62mN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra cosa que podemos hacer es usar un mapeo de un dato a otro. Esto significa que le damos a pandas algún objeto que contenga una correspondencia entre un dato y otro para que realice una conversión.\n",
        "\n",
        "map nos permite pasarle tanto un diccionario como una función para realizar la conversión de un dato a otro."
      ],
      "metadata": {
        "id": "oKDH9H7H64SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = pd.read_csv('../../Datasets/new_york_times_bestsellers-dirty.csv', index_col=0)\n",
        "\n",
        "df_2.head()\n"
      ],
      "metadata": {
        "id": "_MuZlWTz65BO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Digamos que queremos transformar los datos de nuestra columna 'rank.numberInt' para que el 'rankink' esté dado por letras, no por números.\n",
        "\n",
        "Sabemos que hay un valor 'No Rank' en esa columna, así que nuestro diccionario de conversión podría verse así:\n",
        "\n"
      ],
      "metadata": {
        "id": "CiBTsljC7BtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "int_a_letra = {\n",
        "    '1': 'a',\n",
        "    '2': 'b',\n",
        "    '3': 'c',\n",
        "    '4': 'd',\n",
        "    '5': 'e',\n",
        "    '6': 'f',\n",
        "    '7': 'g',\n",
        "    '8': 'h',\n",
        "    '9': 'i',\n",
        "    '10': 'j',\n",
        "    '11': 'k',\n",
        "    '12': 'l',\n",
        "    '13': 'm',\n",
        "    '14': 'n',\n",
        "    '15': 'o',\n",
        "    '16': 'p',\n",
        "    'No Rank': 'z'\n",
        "}\n"
      ],
      "metadata": {
        "id": "159-DtBM7EpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo aplicamos usando map:\n",
        "\n"
      ],
      "metadata": {
        "id": "oJgeNkKD7HwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['rank.numberInt'].map(int_a_letra).head(20)\n"
      ],
      "metadata": {
        "id": "sQM6TiCP7JVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "También podemos usar una función para map. Por ejemplo esta función que realiza una correspondencia entre el precio de un libro y su representación en string:\n",
        "\n"
      ],
      "metadata": {
        "id": "qxlxY0X_7K9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def double_to_money(value):\n",
        "    \n",
        "    return f'${value} USD'\n"
      ],
      "metadata": {
        "id": "mdzCvLxK7Mvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['price.numberDouble'].map(double_to_money)\n"
      ],
      "metadata": {
        "id": "Kv7Bo-3Y7W8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo único que tienes que pensar al usar map es: \"¿Este dato tiene una correspondencia con otro dato que pueda representar con un diccionario o una función?\". Y listo.\n",
        "\n"
      ],
      "metadata": {
        "id": "wORPD5i17Z71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## APPLY"
      ],
      "metadata": {
        "id": "jTxZuK3l7dDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra manera de crear correspondencias es aplicando una función a nuestro DataFrame o Serie usando apply.\n",
        "\n",
        "Para una Serie podemos usar apply para aplicar una función \"elemento por elemento\".\n",
        "\n",
        "En DataFrames podemos usar este mismo método para aplicar funciones por filas o por columnas.\n",
        "\n"
      ],
      "metadata": {
        "id": "SzTG65Aj7e1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def years_since_bestseller(value):\n",
        "    \n",
        "    as_datetime = pd.to_datetime(value, unit='ms')\n",
        "    today = pd.to_datetime('today')\n",
        "    difference_in_days = (today - as_datetime).days\n",
        "    in_years = difference_in_days / 365\n",
        "    \n",
        "    return in_years\n"
      ],
      "metadata": {
        "id": "e6G1BWdx7jGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['published_date.numberLong'].apply(years_since_bestseller)\n"
      ],
      "metadata": {
        "id": "IPur9rK_7lwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FILTROS"
      ],
      "metadata": {
        "id": "xvAxVdPJ7v-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los filtros nos sirven para obtener subconjuntos de datos que tengan una cierta característica que necesitamos. Podemos \"filtrar\" solamente los datos que deseamos y dejar fuera datos indeseables.\n",
        "\n",
        "Crear subconjuntos a partir de nuestro conjunto de datos es muy útil para entender mejor la conformación de nuestro dataset y para realizar análisis de muestras del total de nuestros datos.\n",
        "\n",
        "¡Ésta es una de las herramientas que vas a estar usando más a menudo!"
      ],
      "metadata": {
        "id": "Dc8w7bZ171Fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../../Datasets/new_york_times_bestsellers-dirty.csv', index_col=0)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "JZTGgTJP717m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Digamos que queremos todas los records donde el nombre del autor empiece con 'R'. Primero, usamos operadores de comparación (o en este caso, el método str.startswith) para obtener nuestro filtro:"
      ],
      "metadata": {
        "id": "qyZ0GqRe77si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['author'].str.startswith('R')"
      ],
      "metadata": {
        "id": "UBgIXi8179U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo que obtenemos de regreso es una Serie con la misma longitud que la Serie original. Se aplicó el método o la comparación a cada elemento de la Serie original. Estos métodos o comparaciones regresan True o False dependiendo de cada valor. La Serie resultante acumula los Trues y Falses que obtengamos de la comparación o de la aplicación del método.\n",
        "\n",
        "Después, al pasar este filtro al operador de indexación del DataFrame, todas las filas a las que les corresponda un True se mantienen, mientras que las filas a las que les corresponde un False se dejan fuera del subconjunto resultante:"
      ],
      "metadata": {
        "id": "SweTEe7y7_Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['author'].str.startswith('R')].head()\n"
      ],
      "metadata": {
        "id": "YOGMcssd76un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos también guardar nuestros filtros en variables y después utilizarlos:\n",
        "\n"
      ],
      "metadata": {
        "id": "S3NbbU6v8DSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtro_precio_mayor_a_20 = df['price.numberDouble'] > 20\n"
      ],
      "metadata": {
        "id": "WZWAa_vV8Bpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[filtro_precio_mayor_a_20].head()\n"
      ],
      "metadata": {
        "id": "A95Mdh798FFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos incluso aplicar dos o más filtros utilizando operadores lógicos. En este caso, nuestro operador and se representa con un & y el operador or se representa con |:"
      ],
      "metadata": {
        "id": "kP-oDoVA8Hui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtro_rank_numero_uno = df['rank.numberInt'] == '1'\n"
      ],
      "metadata": {
        "id": "Rf_5JR2R8JNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[filtro_precio_mayor_a_20 & filtro_rank_numero_uno].head()\n"
      ],
      "metadata": {
        "id": "NEVtOdBC8Kto"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}