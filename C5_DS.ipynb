{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Funciones vectorizadas y limpieza de datos\n"
      ],
      "metadata": {
        "id": "jn3RF3JKgd_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Aritmética con Series y Funciones vectorizadas**"
      ],
      "metadata": {
        "id": "koHLgDOcghEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "map nos permite aplicar una función a una lista \"elemento por elemento\". Hay una manera todavía más fácil de aplicar este tipo de procesos a una Serie gracias a la aritmética con Series y a las funciones vectorizadas. Aplicar una transformación es tan fácil como esto:"
      ],
      "metadata": {
        "id": "9JNOzsfAgqOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI8-EolQfgJx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "serie_1 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n"
      ],
      "metadata": {
        "id": "EGRXqqhZgzUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recuerdas cómo utilizamos map para aplicar una función elemento por elemento a un arreglo. Podemos utilizar funciones vectorizadas para hacer esto mismo con Series y DataFrames de pandas. Esto resulta sumamente eficiente pues pandas está construido para funcionar de esta manera. Primero que nada, veamos cómo es posible aplicar operaciones aritméticas a Series de pandas y son aplicadas elemento por elemento. Por ejemplo:\n",
        "\n"
      ],
      "metadata": {
        "id": "PVHUlNang1OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "serie_1 + 10\n"
      ],
      "metadata": {
        "id": "JBHohW3vg3za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serie_1 * 10\n"
      ],
      "metadata": {
        "id": "2AEnN0hYg5tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(serie_1 + 10) * 100\n"
      ],
      "metadata": {
        "id": "A7ODztxOhY2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serie_1 * 60 / 100\n"
      ],
      "metadata": {
        "id": "VAYVMWkrhcIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos también aplicar funciones de manera vectorizada a una Serie de pandas. Esto quiere decir que, sin necesidad de utilizar map la función se aplica automáticamente a cada elemento. Vamos a utilizar una librería llamada numpy para probar algunas de estas funciones vectorizadas.\n",
        "\n"
      ],
      "metadata": {
        "id": "cqsuaEfbhlxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "kw1NWu92hoMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.power(serie_1, 2)\n"
      ],
      "metadata": {
        "id": "dH1gmggdhpwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(serie_1)\n"
      ],
      "metadata": {
        "id": "-VdWDPqfhtFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Agregaciones**"
      ],
      "metadata": {
        "id": "kQGh7U54h04A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las agregaciones son una variación de las funciones vectorizadas. Lo que hacen es tomar un arreglo (una Serie, por ejemplo), aplicar una operación a todos los elementos y regresar un resultado único que es la agregación o reducción del arreglo. Una agregación se ve así:\n",
        "\n"
      ],
      "metadata": {
        "id": "IHx91pywjSLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "serie = pd.Series([1, 2, 3, 4, 5])\n"
      ],
      "metadata": {
        "id": "NVJR6V33jU-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serie.sum()\n"
      ],
      "metadata": {
        "id": "OjD0Y0ihjyvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serie.min()\n"
      ],
      "metadata": {
        "id": "vEqa1P-2j0TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serie.max()\n"
      ],
      "metadata": {
        "id": "wdNSdbfgj3Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "serie.max()\n"
      ],
      "metadata": {
        "id": "UPrT8F5aj3rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Funciones vectorizadas y agregaciones con DataFrames**"
      ],
      "metadata": {
        "id": "v6JPALqukDhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos = {\n",
        "    'precio': [34, 54, 223, 78, 56, 12, 34],\n",
        "    'cantidad_en_stock': [3, 6, 10, 2, 5, 45, 2],\n",
        "    'productos_vendidos': [3, 45, 23, 76, 24, 6, 2]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(datos, index=[\"Guadalajara\", \"CDMX\", \"Cuernavaca\", \"Ciudad Juarez\", \"Cancún\", \"Conzumel\", \"Irapuato\"])"
      ],
      "metadata": {
        "id": "van0RnXdokbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "piIYGGTbovfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df * 100"
      ],
      "metadata": {
        "id": "5_gSyT5Fo0x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df + 100) / 2"
      ],
      "metadata": {
        "id": "nVCJlO-Po2lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "También podemos aplicar funciones vectorizadas con el mismo resultado:\n",
        "\n"
      ],
      "metadata": {
        "id": "60Swireco4m6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.power(df, 2)\n"
      ],
      "metadata": {
        "id": "D6hnlKEEPeom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(df)\n"
      ],
      "metadata": {
        "id": "nSAc61pyPg5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sin(df) + 100\n"
      ],
      "metadata": {
        "id": "LJIu4IoDPhZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sum(axis=1)\n"
      ],
      "metadata": {
        "id": "a4INkaSqPk-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.min()\n"
      ],
      "metadata": {
        "id": "7n89C2N-QYC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.min(axis=1)\n"
      ],
      "metadata": {
        "id": "RXEjLNTpQZ9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.max()\n"
      ],
      "metadata": {
        "id": "EpRU2WKqRWZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.max(axis=1)\n"
      ],
      "metadata": {
        "id": "ZQh93lXARYGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Valores NaN**"
      ],
      "metadata": {
        "id": "oCaWxFLqV0cy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los valores NaN (Not a Number) son bastante indeseables porque no podemos utilizarlos para realizar análisis estadístico u operaciones aritméticas. Es por eso que uno de los primeros pasos en la Limpieza de Datos suele ser la eliminación de estos valores.\n",
        "\n",
        "Los NaNs se ven así en un DataFrame:"
      ],
      "metadata": {
        "id": "ePa9LrpFWAzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datos = {\n",
        "    'precio': [34, 54, np.nan, np.nan, 56, 12, 34],\n",
        "    'cantidad_en_stock': [3, 6, 14, np.nan, 5, 2, 10],\n",
        "    'productos_vendidos': [3, 45, 23, np.nan, 24, 6, np.nan]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(datos, index=[\"Morelos\", \"Guerrero\", \"CDMX\", \"Estado de México\", \"Puebla\", \"San Luis\", \"Queretaro\"])"
      ],
      "metadata": {
        "id": "0lRlcpaRWG6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "SNW9mAWnWksV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para contarlos podemos usar una función vectorizada llamada isna, que nos regresa esto:\n",
        "\n"
      ],
      "metadata": {
        "id": "4yKZhf-pWuH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna()\n"
      ],
      "metadata": {
        "id": "_-jzjsYLWlG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "isna regresa True cuando encuentra un NaN y False cuando el valor es válido.\n",
        "\n",
        "Después, podemos contar cuántos NaNs existen usando la agregación sum, que suma 1 por cada True y 0 por cada False:"
      ],
      "metadata": {
        "id": "MZ3ejxqnWz-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum(axis=0)\n"
      ],
      "metadata": {
        "id": "cCFahAxIWw5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum(axis=1)\n"
      ],
      "metadata": {
        "id": "Y66oP5FRW5M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LIMPIANDO NA´s**"
      ],
      "metadata": {
        "id": "6plZMZitW95y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay 3 operaciones básicas que podemos realizar para eliminar NaNs de nuestros datasets:\n",
        "\n",
        "1. Eliminar filas con NaNs\n",
        "2. Eliminar columnas con NaNs\n",
        "3. Llenar los NaNs con algún valor.\n",
        "\n",
        "Exploremos las 3 opciones."
      ],
      "metadata": {
        "id": "2GgMvSmRXCOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Smzhjf44XUDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para limpiar las filas que tengan mínimo 1 valor NaN, se utiliza dropna(axis=0, how='any'):\n",
        "\n"
      ],
      "metadata": {
        "id": "613TPlnHXboE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(axis=0, how='any')\n"
      ],
      "metadata": {
        "id": "e1I1QB7hXZsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con el axis=0 le estamos diciendo que queremos eliminar por filas. Con how='any' le decimos que queremos eliminar cualquier fila que tenga mínimo un NaN.\n",
        "\n",
        "Si quisiéramos eliminar sólo las filas donde todos los valores sean NaN, podemos usar axis='all':"
      ],
      "metadata": {
        "id": "mVorFkqnXf38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(axis=0, how='all')\n"
      ],
      "metadata": {
        "id": "7JYAsqUfXgo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estos resultados no se aplican directamente al DataFrame original. Si queremos que persistan tenemos que asignarlos a otra variable:\n",
        "\n"
      ],
      "metadata": {
        "id": "bk9Gl4mtXkBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped = df.dropna(axis=0, how='all')\n"
      ],
      "metadata": {
        "id": "Dt0JHCh3XknF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Limpiando NaNs por columnas**\n"
      ],
      "metadata": {
        "id": "QWE3z3_ZXsZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a agregar una columna:\n",
        "\n"
      ],
      "metadata": {
        "id": "VjJ_Jba0XuRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['descuento'] = np.nan\n"
      ],
      "metadata": {
        "id": "4q5gUcFRXvqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Aud2aMmqYCaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que por filas, eliminar NaNs por columna también se puede hacer usando ´any´ y ´all´. La única diferencia es que ahora hay que usar axis=1 para que se haga la eliminación por columnas:"
      ],
      "metadata": {
        "id": "2zirAVE9YS8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(axis=1, how='any')\n"
      ],
      "metadata": {
        "id": "FMygiMpXYVBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped = df.dropna(axis=1, how='all')\n"
      ],
      "metadata": {
        "id": "808LFvb7YW-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Llenando NaNs con valores**\n"
      ],
      "metadata": {
        "id": "z4rug4kOYZuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Otra cosa que podemos hacer es llenar los valores NaN con algún otro valor.\n",
        "\n",
        "Por ejemplo, digamos que tenemos este dataset:"
      ],
      "metadata": {
        "id": "RQsLvOUXYbjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "4HnK-pqSYhth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo primero que hay que hacer es eliminar filas y columnas donde todos los valores sean NaN, puesto que no nos sirven de nada:\n",
        "\n"
      ],
      "metadata": {
        "id": "8-5rC4MLY2j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_nans = df.dropna(axis=0, how='all')\n",
        "df_no_nans = df_no_nans.dropna(axis=1, how='all')\n",
        "\n",
        "df_no_nans"
      ],
      "metadata": {
        "id": "uNQQ65SFY30f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, digamos que podemos asumir que si hay un valor NaN en \"productos_vendidos\" es porque no ha sido vendido aún. En ese caso podemos rellenar ese NaN usando fillna:"
      ],
      "metadata": {
        "id": "q3UPFiOqZB8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_nans['productos_vendidos'] = df_no_nans['productos_vendidos'].fillna(0)\n",
        "\n",
        "df_no_nans"
      ],
      "metadata": {
        "id": "IZrjy0i6ZEVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_nans.dropna(axis=0)\n"
      ],
      "metadata": {
        "id": "JWMY8r5kZGPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **LEYENDO CSV**"
      ],
      "metadata": {
        "id": "r3s7owUfZl3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para leer un archivo .csv en pandas, usamos read_csv y le indicamos que el separador (el signo que delimita las columnas en el archivo .csv) es una coma:\n",
        "\n"
      ],
      "metadata": {
        "id": "QFUeCbUGZpKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../../Datasets/melbourne_housing-raw.csv', sep=',')\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "FLUxrZj0ZqCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "id": "dNylj_QeZtSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)\n"
      ],
      "metadata": {
        "id": "lC4lKheQZvC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()\n"
      ],
      "metadata": {
        "id": "ie7jat3MZwvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = df.drop(columns=['BuildingArea', 'YearBuilt'])\n",
        "\n",
        "df_2.isna().sum()"
      ],
      "metadata": {
        "id": "q3YvDhhbZynk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2['Regionname'] = df_2['Regionname'].fillna('Unknown')\n",
        "\n",
        "df_2.isna().sum()"
      ],
      "metadata": {
        "id": "WD6Jef-aaX54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped = df_2.dropna(axis=0, how='any')\n",
        "\n",
        "df_dropped.isna().sum()"
      ],
      "metadata": {
        "id": "sjaczKIyaaQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped.shape\n"
      ],
      "metadata": {
        "id": "RBQK-TnKacyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = pd.ExcelWriter('Report.xlsx')\n",
        "\n",
        "df_dropped.to_excel(writer, sheet_name='Clean',index=False)"
      ],
      "metadata": {
        "id": "a5zLR6MDa_4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('Report.xlsx')"
      ],
      "metadata": {
        "id": "9JTYJatbbHHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reindexando y renombrando columnas**"
      ],
      "metadata": {
        "id": "il7egcXrbih_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpiemos nuestro dataset hasta que esté justo como lo dejamos en el Ejemplo pasado:\n",
        "\n"
      ],
      "metadata": {
        "id": "OuuuPW-ob2rx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped\n"
      ],
      "metadata": {
        "id": "ZCml8Z45drDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, tenemos dos situaciones:\n",
        "\n",
        "La primera es que nuestro índice no coincide con el número de filas que tenemos. En este caso, dado que nuestro índice es secuencial y numérico, y no tiene ningún significado además de eso, nos convendría que reflejara la cantidad de filas que tenemos en nuestro dataset.\n",
        "\n",
        "Para lograr eso vamos a usar el método reset_index:\n",
        "\n"
      ],
      "metadata": {
        "id": "owasesIUdxoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped.reset_index()\n"
      ],
      "metadata": {
        "id": "KFqpj239dxKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuestro índice ya está correcto, pero ahora tenemos un columna llamada index que contiene el índice original. Como no queremos guardar esos datos, agregamos la opción drop=True para eliminar el índice anterior:"
      ],
      "metadata": {
        "id": "55Ql0pzud9mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped.reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "VTUPvIWhd5WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dropped = df_dropped.reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "Ai7r8dUBeCWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora tenemos un problema con los nombres de las columnas: Tienen inconsistencias en la manera cómo están nombradas y algunas incluso tienen errores ortográficos. Vamos a cambiarles los nombres para tener consistencia:\n",
        "\n"
      ],
      "metadata": {
        "id": "8uTI2IvheFQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_name_mapping = {\n",
        "    'Suburb': 'suburb',\n",
        "    'Address': 'address',\n",
        "    'Rooms': 'rooms',\n",
        "    'Type': 'type',\n",
        "    'Price': 'price',\n",
        "    'Method': 'method',\n",
        "    'SellerG': 'seller_g',\n",
        "    'Date': 'date',\n",
        "    'Distance': 'distance',\n",
        "    'Postcode': 'post_code',\n",
        "    'Bedroom2': 'bedrooms',\n",
        "    'Bathroom': 'bathroom',\n",
        "    'Car': 'car',\n",
        "    'Landsize': 'land_size',\n",
        "    'CouncilArea': 'council_area',\n",
        "    'Lattitude': 'latitude',\n",
        "    'Longtitude': 'longitude',\n",
        "    'Regionname': 'region_name',\n",
        "    'Propertycount': 'property_count'\n",
        "}"
      ],
      "metadata": {
        "id": "yR5wAxXOeHrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_renamed = df_dropped.rename(columns=column_name_mapping)\n",
        "\n",
        "df_renamed"
      ],
      "metadata": {
        "id": "2WGwaQejeJ9K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}